{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Encoding and decoding with attention.ipynb","provenance":[{"file_id":"13Y0-fv1SuOJLfldx_3zkqruRQPE4I8Ed","timestamp":1563913452838}],"collapsed_sections":["RjVV77Gb-26J","y9OPQhJsKyH0","9EU3n95LOAAs"]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"saTdF45cytFE","colab_type":"code","colab":{},"cellView":"both"},"source":["#@title\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.autograd import Variable\n","import torch.nn.functional as F\n","import numpy as np\n","\n","# Instantiates the device to be used as GPU/CPU based on availability\n","device_gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Visualization tools\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from IPython.display import clear_output\n","\n","import random\n","print(device_gpu)\n","print(torch.__version__)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tcU3htodsfca","colab_type":"code","colab":{}},"source":["!sudo apt install tesseract-ocr"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ei0HbmnBsiR2","colab_type":"code","colab":{}},"source":["!pip install pytesseract"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cxQkYIaCszwH","colab_type":"code","colab":{}},"source":["import pytesseract\n","import shutil\n","import os\n","import random\n","try:\n","    from PIL import Image\n","except ImportError:\n","    import Image"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"I7j_WqVcw6tg","colab_type":"code","colab":{}},"source":["hindi_alphabets = [chr(alpha) for alpha in range(2304, 2432)]\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bESChOrdw9dL","colab_type":"code","colab":{}},"source":["len(hindi_alphabets)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OhTiLFwKw_2M","colab_type":"code","colab":{}},"source":["hindi_alphabets"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CJ9Ng8jF1YN3","colab_type":"text"},"source":["### Alphabets Setup"]},{"cell_type":"code","metadata":{"id":"FukskssD1bQF","colab_type":"code","colab":{}},"source":["eng_alphabets = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n","pad_char = '-PAD-'\n","\n","eng_alpha2index = {pad_char: 0}\n","for index, alpha in enumerate(eng_alphabets):\n","    eng_alpha2index[alpha] = index+1\n","\n","print(eng_alpha2index)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LQ305fmG1fee","colab_type":"code","colab":{}},"source":["# Hindi Unicode Hex Range is 2304:2432. Source: https://en.wikipedia.org/wiki/Devanagari_(Unicode_block)\n","\n","hindi_alphabets = [chr(alpha) for alpha in range(2304, 2432)]\n","hindi_alphabet_size = len(hindi_alphabets)\n","\n","hindi_alpha2index = {pad_char: 0}\n","for index, alpha in enumerate(hindi_alphabets):\n","    hindi_alpha2index[alpha] = index+1\n","\n","print(hindi_alpha2index)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"l1EvaSs6xYjO","colab_type":"code","colab":{}},"source":["type(hindi_alphabets)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P4zck-xEyAj5","colab_type":"code","colab":{}},"source":["print(hindi_alpha2index)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"A2wcqTapyHj-","colab_type":"code","colab":{}},"source":["import re\n","non_eng_letters_regex = re.compile('[^a-zA-Z ]')\n","\n","# Remove all English non-letters\n","def cleanEnglishVocab(line):\n","    line = line.replace('-', ' ').replace(',', ' ').upper()\n","    line = non_eng_letters_regex.sub('', line)\n","    return line.split()\n","\n","# Remove all Hindi non-letters\n","def cleanHindiVocab(line):\n","    line = line.replace('-', ' ').replace(',', ' ')\n","    cleaned_line = ''\n","    for char in line:\n","        if char in hindi_alpha2index or char == ' ':\n","            cleaned_line += char\n","    return cleaned_line.split()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xsFg-zt12Css","colab_type":"text"},"source":["## Dataset Loading"]},{"cell_type":"code","metadata":{"id":"t-Q3wTQJ0u8I","colab_type":"code","colab":{}},"source":["from torch.utils.data import Dataset\n","import xml.etree.ElementTree as ET\n","\n","class TransliterationDataLoader(Dataset):\n","    def __init__(self, filename):\n","        self.eng_words, self.hindi_words = self.readXmlDataset(filename, cleanHindiVocab)\n","        self.shuffle_indices = list(range(len(self.eng_words)))\n","        random.shuffle(self.shuffle_indices)\n","        self.shuffle_start_index = 0\n","        \n","    def __len__(self):\n","        return len(self.eng_words)\n","    \n","    def __getitem__(self, idx):\n","        return self.eng_words[idx], self.hindi_words[idx]\n","    \n","    def readXmlDataset(self, filename, lang_vocab_cleaner):\n","        transliterationCorpus = ET.parse(filename).getroot()\n","        lang1_words = []\n","        lang2_words = []\n","\n","        for line in transliterationCorpus:\n","            wordlist1 = cleanEnglishVocab(line[0].text)\n","            wordlist2 = lang_vocab_cleaner(line[1].text)\n","\n","            # Skip noisy data\n","            if len(wordlist1) != len(wordlist2):\n","                print('Skipping: ', line[0].text, ' - ', line[1].text)\n","                continue\n","\n","            for word in wordlist1:\n","                lang1_words.append(word)\n","            for word in wordlist2:\n","                lang2_words.append(word)\n","\n","        return lang1_words, lang2_words\n","    \n","    def get_random_sample(self):\n","        return self.__getitem__(np.random.randint(len(self.eng_words)))\n","    \n","    def get_batch_from_array(self, batch_size, array):\n","        end = self.shuffle_start_index + batch_size\n","        batch = []\n","        if end >= len(self.eng_words):\n","            batch = [array[i] for i in self.shuffle_indices[0:end%len(self.eng_words)]]\n","            end = len(self.eng_words)\n","        return batch + [array[i] for i in self.shuffle_indices[self.shuffle_start_index : end]]\n","    \n","    def get_batch(self, batch_size, postprocess = True):\n","        eng_batch = self.get_batch_from_array(batch_size, self.eng_words)\n","        hindi_batch = self.get_batch_from_array(batch_size, self.hindi_words)\n","        self.shuffle_start_index += batch_size + 1\n","        \n","        # Reshuffle if 1 epoch is complete\n","        if self.shuffle_start_index >= len(self.eng_words):\n","            random.shuffle(self.shuffle_indices)\n","            self.shuffle_start_index = 0\n","            \n","        return eng_batch, hindi_batch"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VktTx1gT2MpN","colab_type":"code","colab":{}},"source":["train_data = TransliterationDataLoader('NEWS2012TrainingEnHi13937.xml')\n","test_data = TransliterationDataLoader('NEWS2012RefEnHi1000.xml')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QJMMHeAp6_dp","colab_type":"text"},"source":["### Basic Data Visualization"]},{"cell_type":"code","metadata":{"id":"w_klPsrM5ssa","colab_type":"code","colab":{}},"source":["print(\"Train Set Size:\\t\", len(train_data))\n","print(\"Test Set Size:\\t\", len(test_data))\n","\n","print(\"\\n Simplle data from trian-set\")\n","for i in range(15):\n","  eng, hindi = train_data.get_random_sample()\n","  print(eng + ' - ' + hindi)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RjVV77Gb-26J","colab_type":"text"},"source":["### Encoding the words"]},{"cell_type":"code","metadata":{"id":"Onna3cw_8A8Y","colab_type":"code","colab":{}},"source":["def word_rep(word, letter2index, device = 'cpu'):\n","  rep = torch.zeros(len(word)+1, 1, len(letter2index)).to(device)\n","  for letter_index, letter in enumerate(word):\n","      pos = letter2index[letter]\n","      rep[letter_index][0][pos] = 1\n","  pad_pos = letter2index[pad_char]\n","  rep[letter_index+1][0][pad_pos] = 1\n","  return rep\n","\n","def gt_rep(word, letter2index, device = 'cpu'):\n","  gt_rp = torch.zeros([len(word)+1, 1], dtype= torch.long).to(device)\n","  for letter_index, letter in enumerate(word):\n","    pos = letter2index[letter]\n","    gt_rp[letter_index][0] = pos\n","  gt_rp[letter_index+1][0] = letter2index[pad_char]\n","  return gt_rp"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cquA13TcAoOX","colab_type":"code","colab":{}},"source":["eng, hindi = train_data.get_random_sample()\n","eng_rep = word_rep(eng, eng_alpha2index)\n","print(eng, eng_rep)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i8zLARIiAvv1","colab_type":"code","colab":{}},"source":["hindi_gt = gt_rep(hindi, hindi_alpha2index)\n","print(hindi, hindi_gt)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PakUde6FA8Qx","colab_type":"code","colab":{}},"source":["p = 'उर्मिमाला'\n","len(p)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zbrZCDSABlkK","colab_type":"code","colab":{}},"source":["MAX_OUTPUT_CHARS = 30\n","class Transliteration_EncoderDecoder(nn.Module):\n","    \n","    def __init__(self, input_size, hidden_size, output_size, verbose=False):\n","        super(Transliteration_EncoderDecoder, self).__init__()\n","        \n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        \n","        self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n","        self.decoder_rnn_cell = nn.GRU(output_size, hidden_size)\n","        \n","        self.h2o = nn.Linear(hidden_size, output_size)\n","        self.softmax = nn.LogSoftmax(dim=2)\n","        \n","        self.verbose = verbose\n","        \n","    def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n","        \n","        # encoder\n","        out, hidden = self.encoder_rnn_cell(input)\n","        \n","        if self.verbose:\n","            print('Encoder input', input.shape)\n","            print('Encoder output', out.shape)\n","            print('Encoder hidden', hidden.shape)\n","        \n","        # decoder\n","        decoder_state = hidden\n","        decoder_input = torch.zeros(1, 1, self.output_size).to(device)\n","        outputs = []\n","        \n","        if self.verbose:\n","            print('Decoder state', decoder_state.shape)\n","            print('Decoder input', decoder_input.shape)\n","        \n","        for i in range(max_output_chars):\n","            \n","            out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n","            \n","            if self.verbose:\n","                print('Decoder intermediate output', out.shape)\n","            \n","            out = self.h2o(decoder_state)\n","            out = self.softmax(out)\n","            outputs.append(out.view(1, -1))\n","            \n","            if self.verbose:\n","                print('Decoder output', out.shape)\n","                self.verbose = False\n","            \n","            max_idx = torch.argmax(out, 2, keepdim=True)\n","            if not ground_truth is None:\n","                max_idx = ground_truth[i].reshape(1, 1, 1)\n","            one_hot = torch.FloatTensor(out.shape).to(device)\n","            one_hot.zero_()\n","            one_hot.scatter_(2, max_idx, 1)\n","            \n","            decoder_input = one_hot.detach()\n","            \n","        return outputs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"V36501YJF7ri","colab_type":"code","colab":{}},"source":["net = Transliteration_EncoderDecoder(len(eng_alpha2index), 256, len(hindi_alpha2index), verbose=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tZChcJFFKwO7","colab_type":"code","colab":{}},"source":["def infer(net, eng, shape, device=\"cpu\"):\n","  input = word_rep(eng, eng_alpha2index, device)\n","  outputs = net(input, shape, device)\n","  return outputs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"l1hTxCQ1F8WZ","colab_type":"code","colab":{}},"source":["out = infer(net, 'INDIA', 30)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y9OPQhJsKyH0","colab_type":"text"},"source":["### Encoder- Decoder with Attention"]},{"cell_type":"code","metadata":{"id":"6EWWOyJBGAOv","colab_type":"code","colab":{}},"source":["class Transliteration_EncoderDecoder_Attention(nn.Module):\n","    \n","    def __init__(self, input_size, hidden_size, output_size, verbose=False):\n","        super(Transliteration_EncoderDecoder_Attention, self).__init__()\n","        \n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        \n","        self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n","        self.decoder_rnn_cell = nn.GRU(hidden_size*2, hidden_size)\n","        \n","        self.h2o = nn.Linear(hidden_size, output_size)\n","        self.softmax = nn.LogSoftmax(dim=2)\n","        \n","        self.U = nn.Linear(self.hidden_size, self.hidden_size)\n","        self.W = nn.Linear(self.hidden_size, self.hidden_size)\n","        self.attn = nn.Linear(self.hidden_size, 1)\n","        self.out2hidden = nn.Linear(self.output_size, self.hidden_size)   \n","        \n","        self.verbose = verbose\n","        \n","    def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n","        \n","        # encoder\n","        encoder_outputs, hidden = self.encoder_rnn_cell(input)\n","        encoder_outputs = encoder_outputs.view(-1, self.hidden_size)\n","        \n","        if self.verbose:\n","            print('Encoder output', encoder_outputs.shape)\n","        \n","        # decoder\n","        decoder_state = hidden\n","        decoder_input = torch.zeros(1, 1, self.output_size).to(device)\n","        \n","        outputs = []\n","        U = self.U(encoder_outputs)\n","        \n","        if self.verbose:\n","            print('Decoder state', decoder_state.shape)\n","            print('Decoder intermediate input', decoder_input.shape)\n","            print('U * Encoder output', U.shape)\n","        \n","        for i in range(max_output_chars):\n","            \n","            W = self.W(decoder_state.view(1, -1).repeat(encoder_outputs.shape[0], 1))\n","            V = self.attn(torch.tanh(U + W))\n","            attn_weights = F.softmax(V.view(1, -1), dim = 1) \n","            \n","            if self.verbose:\n","                print('W * Decoder state', W.shape)\n","                print('V', V.shape)\n","                print('Attn', attn_weights.shape)\n","            \n","            attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n","                                 encoder_outputs.unsqueeze(0))\n","            \n","            embedding = self.out2hidden(decoder_input)\n","            decoder_input = torch.cat((embedding[0], attn_applied[0]), 1).unsqueeze(0)\n","            \n","            if self.verbose:\n","                print('Attn LC', attn_applied.shape)\n","                print('Decoder input', decoder_input.shape)\n","                \n","            out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n","            \n","            if self.verbose:\n","                print('Decoder intermediate output', out.shape)\n","                \n","            out = self.h2o(decoder_state)\n","            out = self.softmax(out)\n","            outputs.append(out.view(1, -1))\n","            \n","            if self.verbose:\n","                print('Decoder output', out.shape)\n","                self.verbose = False\n","            \n","            max_idx = torch.argmax(out, 2, keepdim=True)\n","            if not ground_truth is None:\n","                max_idx = ground_truth[i].reshape(1, 1, 1)\n","            one_hot = torch.zeros(out.shape, device=device)\n","            one_hot.scatter_(2, max_idx, 1) \n","            \n","            decoder_input = one_hot.detach()\n","            \n","        return outputs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EELxY70CK6cv","colab_type":"code","colab":{}},"source":["net_attn = Transliteration_EncoderDecoder_Attention(len(eng_alpha2index), 256, len(hindi_alpha2index), verbose=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qXehkNHdK8LZ","colab_type":"code","colab":{}},"source":["out = infer(net_attn, 'INDIA', 30)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"h9yJYoZCK-LO","colab_type":"code","colab":{}},"source":["print(len(out))\n","for i in range(len(out)):\n","    print(out[i].shape, list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ddn1wbqKLCLl","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gM95OrWjN9AW","colab_type":"text"},"source":["## Training"]},{"cell_type":"markdown","metadata":{"id":"9EU3n95LOAAs","colab_type":"text"},"source":["### Core Trainer"]},{"cell_type":"code","metadata":{"id":"Yg6Df6lYOEeO","colab_type":"code","colab":{}},"source":["def train_batch(net, opt, criterion, batch_size, device = 'cpu', teacher_force = False):\n","    \n","    net.train().to(device)\n","    opt.zero_grad()\n","    eng_batch, hindi_batch = train_data.get_batch(batch_size)\n","    \n","    total_loss = 0\n","    for i in range(batch_size):\n","        \n","        input = word_rep(eng_batch[i], eng_alpha2index, device)\n","        gt = gt_rep(hindi_batch[i], hindi_alpha2index, device)\n","        outputs = net(input, gt.shape[0], device, ground_truth = gt if teacher_force else None)\n","        \n","        for index, output in enumerate(outputs):\n","            loss = criterion(output, gt[index]) / batch_size\n","            loss.backward(retain_graph = True)\n","            total_loss += loss\n","        \n","    opt.step()\n","    return total_loss/batch_size"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iCdIq_VDOJM6","colab_type":"text"},"source":["### Training Helper"]},{"cell_type":"code","metadata":{"id":"EtCu84gtOGad","colab_type":"code","colab":{}},"source":["def train_setup(net, lr = 0.01, n_batches = 100, batch_size = 10, momentum = 0.9, display_freq=5, device = 'cpu'):\n","    \n","    net = net.to(device)\n","    criterion = nn.NLLLoss(ignore_index = -1)\n","    opt = optim.Adam(net.parameters(), lr=lr)\n","    teacher_force_upto = n_batches//3\n","    \n","    loss_arr = np.zeros(n_batches + 1)\n","    \n","    for i in range(n_batches):\n","        loss_arr[i+1] = (loss_arr[i]*i + train_batch(net, opt, criterion, batch_size, device = device, teacher_force = i<teacher_force_upto ))/(i + 1)\n","        \n","        if i%display_freq == display_freq-1:\n","            clear_output(wait=True)\n","            \n","            print('Iteration', i, 'Loss', loss_arr[i])\n","            plt.figure()\n","            plt.plot(loss_arr[1:i], '-*')\n","            plt.xlabel('Iteration')\n","            plt.ylabel('Loss')\n","            plt.show()\n","            print('\\n\\n')\n","            \n","    torch.save(net, 'model.pt')\n","    return loss_arr"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bRzYOk_uOOCC","colab_type":"code","colab":{}},"source":["net = Transliteration_EncoderDecoder(len(eng_alpha2index), 256, len(hindi_alpha2index))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CcbrthVazdIO","colab_type":"code","colab":{}},"source":["net.load_state_dict(torch.load(\"translatorenglishtohindinet1.pt\"))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oMuWjj9SOQLM","colab_type":"code","colab":{}},"source":["train_setup(net, lr=0.001, n_batches=2500, batch_size = 64, display_freq=10, device = device_gpu)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"glwBcFn6dmh_","colab_type":"code","colab":{}},"source":["out = infer(net, 'INDIA', 30)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4LQDgvxdgFGw","colab_type":"code","colab":{}},"source":["str = []\n","print(len(out))\n","for i in range(len(out)):\n","    print(out[i].shape, list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))])\n","    str.append(list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))])\n","    \n","print(str)\n","l=\"\"\n","for i in str:\n","  if i == '-PAD-':\n","    break;\n","  l+=i\n","print(l)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0PESjQZtOe9I","colab_type":"text"},"source":["### Training with Attention"]},{"cell_type":"code","metadata":{"id":"-_MgDLYMOZcU","colab_type":"code","colab":{}},"source":["net_att = Transliteration_EncoderDecoder_Attention(len(eng_alpha2index), 256, len(hindi_alpha2index))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NecuODEjxKO2","colab_type":"code","colab":{}},"source":["net_att.load_state_dict(torch.load(\"translatorenglishtohindinet_att1.pth\"))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EfLYJAksOlly","colab_type":"code","colab":{}},"source":["#loss_history = train_setup(net_att, lr=0.002, n_batches=2000, batch_size = 128, display_freq=10, device = device_gpu)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hcrDIK7NDZCG","colab_type":"code","colab":{}},"source":["#torch.save(net_att.state_dict(), \"translatorenglishtohindinet_att1.pth\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q_tBbI_7u6XT","colab_type":"code","colab":{}},"source":["out = infer(net_att, 'SHASHAANK', 30)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"af4TLHlWvCa2","colab_type":"code","colab":{}},"source":["str = []\n","print(len(out))\n","for i in range(len(out)):\n","    print(out[i].shape, list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))])\n","    str.append(list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))])\n","    \n","#print(str)\n","\n","l=\"\"\n","for i in str:\n","  if i == '-PAD-':\n","    break;\n","  l+=i\n","print(l)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6FvsS1bCOqSm","colab_type":"text"},"source":["## Inference"]},{"cell_type":"code","metadata":{"id":"kZZSMHeVOsQa","colab_type":"code","colab":{}},"source":["def test(net, word, device = 'cpu'):\n","    net = net.eval().to(device)\n","    outputs = infer(net, word, 30, device)\n","    hindi_output = ''\n","    for out in outputs:\n","        val, indices = out.topk(1)\n","        index = indices.tolist()[0][0]\n","        if index == 0:\n","            break\n","        hindi_char = hindi_alphabets[index+1]\n","        hindi_output += hindi_char\n","    print(word + ' - ' + hindi_output)\n","    return hindi_output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b6_43ETwOu6J","colab_type":"code","colab":{}},"source":["def calc_accuracy(net, device = 'cpu'):\n","    net = net.eval().to(device)\n","    predictions = []\n","    accuracy = 0\n","    for i in range(len(test_data)):\n","        eng, hindi = test_data[i]\n","        gt = gt_rep(hindi, hindi_alpha2index, device)\n","        outputs = infer(net, eng, gt.shape[0], device)\n","        correct = 0\n","        for index, out in enumerate(outputs):\n","            val, indices = out.topk(1)\n","            hindi_pos = indices.tolist()[0]\n","            if hindi_pos[0] == gt[index][0]:\n","                correct += 1\n","        \n","        accuracy += correct/gt.shape[0]\n","    accuracy /= len(test_data)\n","    return accuracy"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_D0Cyx7ROx3o","colab_type":"code","colab":{}},"source":["#accuracy = calc_accuracy(net) * 100\n","accuracy_attn = calc_accuracy(net_att) * 100\n","#print('Accuracy w/o attention ', accuracy)\n","print('Acurracy with attention', accuracy_attn)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jcVaBKsrcBov","colab_type":"code","colab":{}},"source":["accuracy_attn = calc_accuracy(net_att) * 100\n","print('Acurracy with attention', accuracy_attn)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NM2ChRxIsKdk","colab_type":"code","colab":{}},"source":["extractedInformation = pytesseract.image_to_string(Image.open('mumbai.jpg'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eGvFOC5Vs9Ct","colab_type":"code","colab":{}},"source":["extractedInformation = extractedInformation.upper()\n","print(extractedInformation)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"s4wWtjvluudD","colab_type":"code","colab":{}},"source":["def cleanEnglishVocab1(line):\n","    line = line.replace('-', ' ').replace(',', ' ').upper()\n","    line = non_eng_letters_regex.sub('', line)\n","    return line"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GlN5ZGPNvb8C","colab_type":"code","colab":{}},"source":["print(cleanEnglishVocab1(extractedInformation))\n","low = cleanEnglishVocab1(extractedInformation)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"igYYlcdNIeNt","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OUg8xnRpO2x5","colab_type":"code","colab":{}},"source":["g = low\n","g = g.upper()\n","sg = g.split()\n","for i in sg:\n","  out = infer(net_att, i, 30)\n","  str = []\n","  #print(len(out))\n","  for i in range(len(out)):\n","      #print(out[i].shape, list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))])\n","      str.append(list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))])\n","\n","  #print(str)\n","\n","  l=\"\"\n","  for i in str:\n","    if i == '-PAD-':\n","      break;\n","    l+=i\n","  print(l, end =\" \")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"v2ru8Zw3tE2f","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}